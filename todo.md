# Todo
- Add:
  - https://huggingface.co/bartowski/Phi-3.1-mini-128k-instruct-GGUF
  - https://huggingface.co/bartowski/Phi-3.5-mini-instruct-GGUF
  - https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF
  - https://huggingface.co/bartowski/Qwen2.5-Coder-7B-Instruct-abliterated-GGUF
  - https://huggingface.co/bartowski/Qwen2.5-Coder-7B-Instruct-GGUF
- Experiment Multimodality with Llama 3.2 Vision 11B (text + images in / text out)
- Provide the chat history in the `context_aware_answer`
- Experiment Agentic Patterns:
  - https://weaviate.io/blog/what-is-agentic-rag
  - https://github.com/neural-maze/agentic_patterns
  - https://www.youtube.com/watch?v=ApoDzZP8_ck
  - Google Search with LLM:
    - https://huggingface.co/blog/nand-tmp/google-search-with-llm
    - https://blog.nextideatech.com/how-to-use-google-search-with-langchain-openai/
    - https://medium.com/@reynxzz/rag-with-gemini-google-search-and-bq-vector-search-for-content-personalization-08fe7dab6b33
    - https://newspaper.readthedocs.io/en/latest/
- Investigate Chroma batch querying: https://github.com/langchain-ai/langchain/blob/907c758d67764385828c8abad14a3e64cf44d05b/libs/community/langchain_community/vectorstores/chroma.py#L42
- Make docker container.
- Test Flash attention:
  - https://github.com/ggerganov/llama.cpp/pull/5021
- Investigate V-RAG (Vision RAG) https://github.com/Softlandia-Ltd/vision-is-all-you-need
