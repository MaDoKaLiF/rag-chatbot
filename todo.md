# Todo
- Add the following models:
  - https://huggingface.co/bartowski/Qwen2.5-Coder-7B-Instruct-abliterated-GGUF
  - https://huggingface.co/bartowski/Qwen2.5-Coder-7B-Instruct-GGUF
- Provide the chat history in the `context_aware_answer`.
- Experiment Multimodality with Llama 3.2 Vision 11B (text + images in / text out)
  - The model is currently not supported by llama.cpp https://github.com/ggerganov/llama.cpp/issues/9643
  - Is it supported just by [(Ollama,](https://github.com/ollama/ollama) so we need to use the Python API to create an additional client.
  - https://github.com/ollama/ollama-python/tree/main
  - https://github.com/ollama/ollama-python/tree/main/examples
  - https://ollama.com/library/llama3.2-vision:11b
  - Take also a look here: https://huggingface.co/unsloth
- Experiment Agentic Patterns:
  - https://weaviate.io/blog/what-is-agentic-rag
  - https://github.com/neural-maze/agentic_patterns
  - https://www.youtube.com/watch?v=ApoDzZP8_ck
  - Google Search with LLM:
    - https://huggingface.co/blog/nand-tmp/google-search-with-llm
    - https://blog.nextideatech.com/how-to-use-google-search-with-langchain-openai/
    - https://medium.com/@reynxzz/rag-with-gemini-google-search-and-bq-vector-search-for-content-personalization-08fe7dab6b33
    - https://newspaper.readthedocs.io/en/latest/
    - https://github.com/AstraBert/PrAIvateSearch
- Explore long term memory: https://help.openai.com/en/articles/8590148-memory-faq
- Investigate Chroma batch querying: https://github.com/langchain-ai/langchain/blob/907c758d67764385828c8abad14a3e64cf44d05b/libs/community/langchain_community/vectorstores/chroma.py#L42
- Make docker container.
- Test Flash attention:
  - https://github.com/ggerganov/llama.cpp/pull/5021
- Investigate V-RAG (Vision RAG) https://github.com/Softlandia-Ltd/vision-is-all-you-need
